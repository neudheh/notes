## Binary tree
- ==A binary tree is a tree data structure where two nodes have at most two children, the left child and the right child==
## Binary search tree
- ==A binary search tree is a type of binary search tree, where for each node, all of the node in the left subtree are lesser than or equal to the node's value, and the value of all the nodes in the right subtree are greater than the node's value==
- This makes it useful for searching and retrieving data
![[bst structure.png]]
- It is represented by nodes connected by edges
- A tree's topmost node is called a root node
- A node that has a sub-node is called a parent
- A node can have 0, 1, or 2 children
- Nodes with no children are called leaf nodes

## OOP implementation
### Node object
- The node object has the data, and two pointers to the left and right child
```python
class Node:
	def __init__(self, data):
		self.data = data
		self.left = None
		self.right = None
```
### Insertion
1. If the tree is empty, insert at the root node
2. Start from the root node
3. If the data is greater than the current node, go to the right subtree and repeat
4. If the data is lesser than the current node, go to the left subtree and repeat
### Searching
1. Start from the root node
2. If the data being searched is greater than the current node, go to the right subtree and repeat
3. If the data being searched is lesser than the current node, go to the left subtree and repeat
4. If the data being searched is equal to the current node, return
```pseduo
PROCEDURE insert (self, data)
	new_node = Node(data)
	IF self.root IS NONE
		THEN
			self.root <- new_node
		ELSE
			// traverses the bst
			inserted = FALSE
			curr = self.head
			WHILE inserted = FALSE DO
				IF data > curr.data
					THEN
						IF curr.right IS NONE
							THEN
								curr.right = new_node
								inserted <- TRUE
							ELSE
								curr = curr.right
						ENDIF
					ELSE
						IF curr.left IS NONE
							THEN
								curr.left = new_node
								inserted <- TRUE
							ELSE
								curr = curr.left
						ENDIF
				ENDIF
			ENDWHILE
	ENDIF
ENDPROCEDURE

FUNCTION search (self, data) RETURNS BOOLEAN
	curr <- self.root
	WHILE curr IS NOT NONE
		IF curr.data = data
			THEN
				RETURN TRUE
			ELSE
				IF data > curr.data
					THEN
						curr <- curr.right
					ELSE
						curr <- curr.left
				ENDIF
		ENDIF
	ENDWHILE
	RETURN FALSE
ENDFUNCTION
```
```python
 class Node:
	def __init__(self, data):
		self.data = data
		self.left = None
		self.right = None
		
class BST:
	def __init__(self):
		self.root = None

	def insert(self, data):
		if self.root == None:
			self.root = Node(data)
			return
		inserted = False
		curr = self.root
		while not inserted:
			if data <= curr.data:
				if curr.left == None
					curr.left = Node(data)
					inserted = True
				else:
					curr = curr.left
			else:
				if curr.right == None:
					curr.right = Node(data)
					inserted = True
				else:
					curr = curr.right	
			
	def search(self, data):
		curr = self.root
		while curr != None:
			if data == curr.data:
				return curr
			elif data < curr.data:
				curr = curr.left
			elif data > curr.data:
				curr = curr.right
		# the search has failed otherwise
```
## Deleting
### Leaf node
- Simply remove the pointer pointing to the lead node
### One child
- Replace the node that is being deleted with its child node, and its descendants
![[bst deletion one child.png]]
### Two children
- Search for the next node in order (e.g. the next bigges node after 3 is 4)
- Found by finding the smallest value in the right subtree after being deleted
- Replace the node that is being deleted with the next biggest node (replace the data of the node being deleted, and delete the next biggest node)
## Update
- Simply delete the previous node, and insert the new data
## Array implementation
- The pointers store the index of the child nodes, and none or -1 can indicate no further nodes
![[bst array implementation.png]]
## Time complexity
- When there is a balanced binary tree, where the height difference of the left and right subtrees is no more than 1, the height of the tree becomes $\log n$, where $n$ is the number of nodes
- To find an element in the second level, we will need 2 comparisons, the third level would need 3, etc
- Hence the time complexity is $\Omega(\log n)$
- If the tree is not balanced, we may have to travel from the root node to the deepest leaf node, causing the height of the tree to be $n$
- This causes the time complexity to become $O(n)$
- The difference in time complexity is large, and we may need to rebalance the tree to maintain search performance
## Traversal
- To traverse a tree, we will need to recurse on its left and right subtrees
### Pre-order
- Preorder is the data at the node, followed by left subtree, right subtree
```pseudo
PROCEDURE preorder (curr)
	IF curr is NOT NONE
		THEN
			OUTPUT curr.data
			preorder(curr.left)
			preorder(curr.right)
	ENDIF
ENDPROCEDURE
```
```python
def preorder_traversal(self, node):
	if node == None:
		return
	print(node.data)
	self.preorder_traversal(node.left)
	self.preorder_traversal(node.right)
```
### In-order
- In-order is the left subtree, then the node, then the right subtree
```pseudo
PROCEDURE inorder (curr)
	IF curr is NOT NONE
		THEN
			inorder(curr.left)
			OUTPUT curr.data
			inorder(curr.right)
	ENDIF
ENDPROCEDURE
```
```python
def inorder_traversal(self, node):
	if node == None:
		return
	self.inorder_traversal(node.left)
	print(node.data)
	self.inorder_traversal(node.right)
```
### Post-order
- Post-order is the left subtree, then the right subtree, then the node
```pseudo
PROCEDURE postorder (curr)
	IF curr is NOT NONE
		THEN
			postorder(curr.left)
			postorder(curr.right)
			OUTPUT curr.data
	ENDIF
ENDPROCEDURE
``````
```python
def postorder_traversal(self, node):
	if node == None:
		return
	self.postorder_traversal(node.left)
	self.postorder_traversal(node.right)
	print(node.data)
```
