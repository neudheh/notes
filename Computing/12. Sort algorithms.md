## Bubble sort
### Non-optimised
1. Compare the first and second values, if the first value is larger than the second, swap them
2. Compare the second and third values, if the second value is larger than the third, swap them
3. Keep comparing adjacent values, swapping if necessary, until the last two values in the list have been processed
4. When we complete the first pass through an entire array, the largest value is in the correct position, but the other values may or may not be in the correct order
5. We need to work through the entire array again and again with each pass having one lesser value to compare
```pseudo
PROCEDURE bubble_sort (x: array)
	FOR passes <- 0 TO LENGTH OF X - 2
		FOR i <- 0 TO LENGTH OF X - 2 - passes
			IF x[i] > x[i+1]
				THEN
					x[i], x[i+1] = x[i+1], x[1]
			ENDIF
		ENDFOR i
	ENDFOR passes
ENDPROCEDURE
```
- The values to be sorted may already be in the correct order before the outer loop has been through all its iterations
- E.g. after the third pass, the values are in the correct order, but the algorithm will continue to run
- This means that we are making comparisons when no further swaps need to be made
![[room to optimize.jpg]]
### Optimised
- If we go through one pass without swapping any values, this means that the values must be in the correct order
- We can use a variable `swapped` to store whether a swap has taken place
- When we swap a pair of value, we set `swapped` to True, indicating that the list was not swapped
- If `swapped` is false at the end of one pass through the list, this means that none of the values are swapped, and the list must be sorted, and we can exit the algorithm
- This allows us to cut down on any unnecessary comparisons and passes, optimising the algorithm
```pseudo
PROCEDURE optimised_bubble_sort (x: ARRAY)
	swapped <- TRUE
	passes <- 0
	WHILE swapped = TRUE DO
		swapped <- FALSE
		FOR i <- 0 TO LENGTH OF x - 2 - passes
			IF x[i] > x[i+1]
				THEN
					x[i], x[i+1] <- x[i+1], x[i]
					swapped <- TRUE
			ENDIF
		ENDFOR
		passes <- passes + 1
	ENDWHILE
ENDPROCEDURE
```
- Best case time complexity is $\Omega(n)$, when we are given a sorted list, we only need one pass of $n-1$ comparisons of the values in the list to check that it is sorted
- Worst case time complexity is $O(n^2)$ as the non-optimised bubble sort algorithm will need to make $(n-1)\times(n-2)$ comparisons to complete the sort
## Insertion sort
- Insertion sort divides the array into two parts, sorted and unsorted
- Unsorted elements are inserted one by one into their sorted place
1. Make the first element in the array a part of the sorted
2. Consider the next element in the unsorted array, if it is smaller than the first, we swap them
3. Consider the third element in the array, we swap it leftwards until it is in ints proper place with the first two elements
4. Repeat until the whole array is sorted
```pseudo
PROCEDURE insertion_sort (x: array)
	FOR i <- 1 TO LENGTH OF x - 1
		curr <- x[i]
		pos = i
		WHILE pos > 0 AND curr < x[pos-1] DO
			x[pos] <- x[pos-1]
			pos <- pos - 1
		ENDWHILE
		x[pos] <- curr 
	ENDFOR
ENDPROCEDURE
```
## Time complexity
- The outer for loop in insertion sort always iterates $n-1$ times
- The inner loop will make $n-1$ comparisons in the best case if all the values are all in the correct order
- The inner while loop will make $1+2+3+...+(n-1)$ comparisons in the worst case
- Best case time complexity of $\Omega(n)$
- Worst case time complexity of $O(n^2)$
## Merge sort
- Merge sort is a divide and conquer algorithm that recursively uses two functions
- One splits the array into half, and one merges both halves, producing a sorted array
### Merge function
- If we have two sorted lists in ascending order, `List1` and `List2`, we compare the first item in both lists
- If the first item in `List1` is smaller than that in `List2`, the first item is removed from `List1` and added to a new list, and vice versa
- The comparison is repeated until either `List1` or `List2` becomes empty, and the remaining items on the list are added to the new list and the merge is complete
```pseudo
FUNCTION merge (array1: ARRAY, array2: ARRAY) RETURNS ARRAY
	i <- 0
	j <- 0
	new_array <- []
	WHILE i < LENGTH OF array1 and j < LENGTH OF array2 DO
		IF array1[i] < array2[j] 
			THEN
				APPEND array1[i] TO new_array
				i <- i + 1
			ELSE
				APPEND array2[j] TO new_array
				j <- j +1
		ENDIF
	ENDWHILE
	IF i = LENGTH OF array2
		THEN
			new_list <- new_list + array2[j:]
		ELSE
			new_list <- new_list + array1[i:]
	ENDIF
	RETURN new_list
ENDFUNCTION
```
### Merge sort function
- The function recursively divides an unsorted array into subarrays, until each contains one element
- Then, it merges to subarrays into a sorted subarray, until there is only one sorted array
```pseduo
FUNCTION merge_sort (x: ARRAY) RETURNS ARRAY
	IF LENGTH OF x <= 1:
		THEN
			RETURN x
		ELSE
			mid <- LENGTH OF x DIV 2
			RETURN merge(merge_sort(x[:MID]), merge_sort(x[MID:]))
	ENDIF
ENDFUNCTION
```
### Time complexity
- The time complexity of dividing the arrays is $O(\log n)$, and the time complexity of merging the subarrays is $O(n)$
- Thus, merge sort has a time complexity of $O(n\log n)$
- The time complexity of best and worst cases is the same, as merge sort always divides the arrays into two halves and takes linear time to merge both halves
## Quicksort
### Out-of-place
- Quicksort first chooses a pivot element, which can be any element in the array 
- The algorithm then partitions the array around the pivot
- Every element lesser than the pivot is placed in a `less_than` array, and every element greater than or equal to the pivot is placed in a `greater_equal` array
- Eventually, those elements are combined in order by first inserting the elements that are `less_than` , then those that are equal, then finally those that are in `greater_equal`
```pseudo
FUNCTION quicksort(A: ARRAY) RETURNS ARRAY
	IF LENGTH OF A < 1
		THEN
			RETURN []
	pivot <- A[0]
	less_than <- array of all the elements in A that are less than the pivot
	greater_equal <- array of all the elements in A that are greater than or equal to the pivot
	RETURN quicksort(less_than)+ [pivot] + quicksort(greater_equal)
ENDFUNCTION
```
- Works well if all the elements are unique
- If they are not, the order of occurrence of two same elements may be altered, making the algorithm an unstable sorting algorithm
### In-place
- Recursion on large data sets can cause the computer to run out of memory, causing a runtime error
- An in-place quicksort algorithm, which uses lesser memory
1. The divide step is performed by scanning the array and using the left index `l`, which advances forwards, and a right index, `r` which advances backwards
2. A swap is performed when `l` is at an element larger than the pivot, and `r` is at an element smaller then the pivot
3. `l` continues to advance forwards, and `r` continues to advance backwards
4. When `l` is greater than `r`, `l` swaps with the pivot, completing the divide step of the in place quickswap
5. The algorithm then recurs on these two subarrays
![[in place quicksort 1.png]]
![[in place quicksort 2.png]]
```
PROCEDURE inplace_quicksort(x: ARRAY, lower: INTEGER, upper: INTEGER)
	IF first < last
		THEN
			pivot <- x[upper]
			l <- lower
			r <- upper - 1
			WHILE l <= r DO
				WHILE x[l] < pivot AND l <= r DO
					l <- l + 1
				ENDWHILE
				WHILE x[r] > pivot AND l <= r DO
					r <- r - 1
				ENDWHILE
				IF x[l] > x[r] 
					THEN
						x[l], x[r] <- x[r], x[l]
						l <- l +1
						r <- r -1
				ENDIF
			ENDWHILE
			x[l], x[upper] <- x[upper], x[l]
			inplace_quicksort(A, lower, l - 1)
			inplace_quicksort(A, l+1, upper)
	ENDIF
ENDPROCEDURE
```
### Time complexity
- Similar to merge sort, quicksort has a time complexity of $\Omega(n\log n )$
- In the worst case, the pivot is always the smallest or largest element, creating partitions of size $n-1$, calling recursive calls $n-1$ times, leading to a time complexity of $O(n^2)$
## Merge sort vs Quicksort
- Quicksort is an unstable sorting technique; it might change the occurrence of two similar elements in the array while sorting.
- Merge sort is a stable algorithm; it doesnâ€™t change the occurrence of similar elements and preserves the order in which these elements appeared in the original array
- Instead of adding elements greater than and equal to the pivot into the `greater_equal` array, elements equal to the pivot can be stored in an `equal` array and elements greater than pivot can be stored in a `greater` array. 
- This will preserve the original order of occurrence of the elements.
```Pseudo
pivot <- element in the middle of the array
less <- an array of all elements in A less than pivot
equal <- an array of all elements in A equal to pivot
greater <- an array of all elements in A greater than pivot
```
- In-place quicksort does not need additional memory space to perform sorting. 
- Merge sort requires a temporary array to merge the sorted arrays.
- Hence, merge sort needs more memory space compared to in-place quicksort.